{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the hidden state: torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "test_sentence = \"This piece of music sounds relaxing.\"\n",
    "\n",
    "#Tokenize the sentence and return PyTorch tensors\n",
    "inputs = tokenizer(test_sentence, return_tensors=\"pt\")\n",
    "\n",
    "# Perform forward pass through the model\n",
    "# Using no_grad() to avoid gradient computation and save memory\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Extract the last hidden state (batch_size, sequence_length, hidden_size)\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "print(\"Shape of the hidden state:\", last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced sentence: This piece of music sounds warm and a little bit wet.\n",
      "Tokenized result: ['[CLS]', 'this', 'piece', 'of', 'music', 'sounds', 'warm', 'and', 'a', 'little', 'bit', 'wet', '.', '[SEP]']\n",
      "Tokens possibly corresponding to the target word: ['warm', 'and', 'a', 'little', 'bit', 'wet']\n",
      "Index range of the target word: 6 to 11\n"
     ]
    }
   ],
   "source": [
    "# Define template sentence and target word\n",
    "template_sentence = \"This piece of music sounds [MASK].\"\n",
    "target_word = \"warm and a little bit wet\"\n",
    "\n",
    "# Replace [MASK] with the target word\n",
    "filled_sentence = template_sentence.replace(\"[MASK]\", target_word)\n",
    "print(\"Replaced sentence:\", filled_sentence)\n",
    "\n",
    "# Tokenize the sentence and retrieve token list\n",
    "inputs = tokenizer(filled_sentence, return_tensors=\"pt\", return_offsets_mapping=True)\n",
    "offset_mapping = inputs.pop(\"offset_mapping\")  # Extract offset mapping\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze())\n",
    "print(\"Tokenized result:\", tokens)\n",
    "\n",
    "# Identify tokens corresponding to the target word\n",
    "target_token_ids = tokenizer(target_word, add_special_tokens=False)[\"input_ids\"]\n",
    "target_tokens = tokenizer.convert_ids_to_tokens(target_token_ids)\n",
    "print(\"Tokens possibly corresponding to the target word:\", target_tokens)\n",
    "\n",
    "# Find contiguous token sequence for the target word\n",
    "def find_sublist(tokens, sub_tokens):\n",
    "    n = len(sub_tokens)\n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        if [t.lstrip(\"##\") for t in tokens[i:i+n]] == [st.lstrip(\"##\") for st in sub_tokens]:\n",
    "            return i, i+n\n",
    "    return None\n",
    "\n",
    "match = find_sublist(tokens, target_tokens)\n",
    "if match:\n",
    "    start_idx, end_idx = match\n",
    "    print(f\"Index range of the target word: {start_idx} to {end_idx-1}\")\n",
    "else:\n",
    "    print(\"Target word not found in the token list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of hidden state: torch.Size([1, 14, 768])\n",
      "torch.Size([6, 768])\n",
      "Shape of averaged vector for target word/phrase: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "# Compute hidden states using the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "last_hidden_state = outputs.last_hidden_state  # Shape: (1, sequence_length, hidden_size)\n",
    "print(\"Shape of hidden state:\", last_hidden_state.shape)\n",
    "\n",
    "# Extract token vectors for the target word and compute the average\n",
    "if match:\n",
    "    target_vectors = last_hidden_state.squeeze()[start_idx:end_idx]  # (sequence_length, hidden_size)\n",
    "    print(target_vectors.shape)\n",
    "    avg_vector = target_vectors.mean(dim=0)\n",
    "    print(\"Shape of averaged vector for target word/phrase:\", avg_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.5907e-01, -3.7284e-01,  2.6824e-01,  4.0523e-01, -2.1251e-01,\n",
       "         2.2506e-01, -1.6994e-01, -1.0682e-01,  6.3423e-02, -1.9893e-01,\n",
       "         6.2298e-01, -3.0936e-01, -6.1058e-02,  8.7082e-01, -2.3974e-01,\n",
       "         5.7228e-01,  1.9898e-01, -1.9546e-01,  3.1596e-01,  4.6010e-01,\n",
       "         3.2079e-01, -2.7677e-01, -8.5889e-01,  8.5149e-01,  4.4705e-01,\n",
       "        -1.1331e-01, -1.0588e-01, -8.7015e-02,  6.7179e-03, -3.3243e-02,\n",
       "         7.4687e-01,  9.1954e-02,  2.4284e-02, -1.8500e-01, -4.0211e-01,\n",
       "        -2.0087e-01, -7.3337e-02, -2.6264e-01, -5.2921e-01,  8.7437e-02,\n",
       "        -7.1026e-01, -3.6878e-01, -4.3237e-01, -1.6795e-01, -1.7243e-02,\n",
       "        -2.1803e-01,  4.6858e-01, -2.7176e-01, -4.1526e-01, -5.1694e-01,\n",
       "         2.2680e-01, -4.1506e-01, -2.7317e-01, -2.5298e-01,  2.8225e-01,\n",
       "         5.0876e-01,  3.7347e-01, -6.5608e-01, -4.7929e-01,  8.3925e-02,\n",
       "        -5.8221e-02,  1.0977e-01,  8.7295e-02, -1.1505e+00,  1.0869e-01,\n",
       "         2.7554e-01, -1.1075e-01, -2.9218e-01, -5.1090e-01, -4.2896e-01,\n",
       "        -2.9697e-01,  1.1252e-03,  1.9206e-02, -1.9206e-01, -2.9025e-01,\n",
       "         7.8933e-02,  2.0229e-01,  4.5675e-01, -2.1584e-02,  3.7927e-01,\n",
       "        -1.0375e+00,  4.3514e-01,  7.5540e-01,  7.1735e-01,  3.1652e-01,\n",
       "        -1.5473e-01,  1.2485e-01,  1.5191e-01, -2.2059e-01, -4.1044e-01,\n",
       "        -3.3595e-01, -1.9025e-01,  2.6406e-01, -1.1907e-01,  6.2031e-01,\n",
       "        -3.1356e-01, -1.1131e-01, -1.7902e-01, -2.4358e-01,  7.7264e-01,\n",
       "        -1.7828e-01, -5.1432e-01, -1.5864e-01,  3.3900e-01,  4.7760e-01,\n",
       "         4.2819e-01,  1.5710e-01,  1.6026e-01,  8.0903e-02,  5.0452e-01,\n",
       "        -1.3089e-01, -2.8559e-01, -2.5261e-01,  1.5073e-01, -8.9864e-02,\n",
       "         4.8994e-01, -2.7764e-01, -4.0455e-01, -4.5290e-01, -2.1177e-01,\n",
       "         3.4628e-01, -7.6823e-01,  2.4373e-01,  8.7140e-02,  2.6385e-01,\n",
       "        -5.0632e-02, -1.8974e-01,  4.2813e-01, -1.3379e-01, -2.5821e-01,\n",
       "         2.9998e-01,  4.6498e-01,  3.5920e-01, -7.1142e-01, -5.4017e-01,\n",
       "         8.7686e-02,  5.3137e-02, -7.7510e-01, -7.0985e-01,  1.7427e-01,\n",
       "         2.9749e-01,  3.7634e-01,  5.0770e-01,  9.2618e-03, -2.4861e-01,\n",
       "        -1.9295e-01, -3.5565e-01,  1.7395e-01, -4.3077e-02, -2.2510e-03,\n",
       "         2.0011e-01, -1.7470e-01, -3.8655e-01, -3.6264e-01,  1.1110e-01,\n",
       "        -3.0890e-01, -5.5188e-01,  3.0567e-02,  2.4761e-02, -2.2375e-01,\n",
       "        -3.7094e-02,  6.6755e-02,  5.4263e-02, -1.4082e-02, -1.0466e-01,\n",
       "         2.6036e-01, -1.4802e-01,  5.5775e-01, -2.8069e-01,  4.1017e-01,\n",
       "        -1.8818e-01, -9.8835e-03,  1.0274e+00, -2.6590e-01,  2.9778e-01,\n",
       "         3.1619e-01,  6.1648e-01,  1.9801e-01,  5.2000e-01,  8.8300e-02,\n",
       "        -2.5721e-01,  3.0627e-01,  5.0681e-01,  2.3339e-01, -1.8128e-01,\n",
       "        -1.7364e-01,  5.0214e-02, -5.6077e-01, -5.6872e-01, -1.8614e-01,\n",
       "        -1.3852e-01, -2.3319e-01, -1.2286e+00,  2.4246e-01, -4.9540e-01,\n",
       "        -4.3267e-01, -5.5195e-02,  6.5225e-01, -2.8500e-01, -2.1845e-01,\n",
       "        -1.1104e-01, -9.1480e-02,  1.3288e-01,  6.2296e-01,  1.4275e-01,\n",
       "        -3.6631e-01,  4.4777e-01,  1.4636e-01, -6.5446e-01,  1.2605e-01,\n",
       "        -5.0384e-01,  1.0356e+00, -1.6073e-01,  2.4523e-01, -5.5652e-01,\n",
       "         2.3331e-01, -2.1178e-01,  3.1399e-01,  1.1640e-01,  2.4443e-01,\n",
       "        -9.0224e-02,  7.7588e-01, -5.3669e-01,  6.4262e-01,  3.1888e-01,\n",
       "         1.1382e+00, -1.9498e-01, -2.8349e-01,  6.2692e-01,  6.9814e-01,\n",
       "        -6.7623e-03, -5.6721e-01,  3.3105e-01,  4.9905e-01, -4.8756e-01,\n",
       "        -1.1428e-01, -5.5222e-02, -2.2428e-01,  1.8153e-01, -8.6228e-01,\n",
       "        -1.4179e-01,  2.3311e-01,  1.2396e-01,  6.4768e-02,  6.5620e-02,\n",
       "         4.2611e-01, -7.1514e-02, -5.3769e-02, -3.4159e-01,  2.1968e-01,\n",
       "        -5.6909e-01, -6.0601e-01, -3.2129e-01, -3.8092e-01, -9.9163e-01,\n",
       "        -4.2977e-01, -5.1719e-01, -3.5337e-02,  6.9013e-02, -8.1088e-02,\n",
       "         1.5080e-02,  1.9163e-02,  2.0255e-01,  1.6197e-01, -8.0164e-01,\n",
       "        -6.3188e-01, -2.8722e-01,  5.2318e-01, -3.1586e-01,  6.4811e-01,\n",
       "         1.0572e-01,  1.5229e-01,  8.8937e-02,  1.1019e+00, -6.1763e-01,\n",
       "        -1.0710e+00,  3.4735e-01,  5.4636e-01, -2.5892e-01, -6.4973e-01,\n",
       "         8.7215e-01,  6.6689e-01, -4.1378e-01, -3.8986e-01, -7.1158e-01,\n",
       "        -6.2693e-01,  1.4071e-01,  7.9190e-01, -2.2288e-01, -1.2103e+00,\n",
       "         1.9893e-01,  3.5237e-01, -9.3485e-02, -1.5484e-01,  1.6916e-01,\n",
       "         3.1195e-01,  4.5283e-01,  9.2128e-02,  6.0120e-01, -5.7923e-01,\n",
       "        -2.5736e-02, -1.6588e-01,  3.0946e-01, -6.0793e-02, -1.0922e-01,\n",
       "         6.4949e-01, -1.5140e-01, -8.2277e-01, -2.6165e+00, -2.2900e-02,\n",
       "         5.0071e-01, -7.2676e-03,  5.3945e-01, -1.7956e-01, -6.7987e-02,\n",
       "        -6.6595e-01, -6.3788e-01,  2.9153e-01,  2.0612e-01, -2.7869e-01,\n",
       "         3.4259e-01, -3.3733e-02,  7.4218e-01, -1.3489e-01,  3.7795e-02,\n",
       "        -5.3495e-01, -7.1222e-02,  4.0161e-01, -4.0458e-01,  4.6190e-01,\n",
       "         3.0638e-01,  2.1440e-01,  1.1272e+00,  1.3982e-02, -1.4797e-01,\n",
       "         7.4034e-02, -9.1417e-01,  2.6517e-01, -4.2167e-01, -1.2773e-01,\n",
       "         6.7308e-01,  6.0788e-02,  2.5406e-01,  5.4515e-02, -4.6943e-01,\n",
       "        -5.4770e-01,  3.6388e-01,  1.9561e-01, -8.3311e-01, -6.0419e-01,\n",
       "         1.8231e-01, -4.0094e-01,  3.6009e-01, -3.7204e-01, -1.4905e-01,\n",
       "        -5.6933e-01, -1.6261e-01,  2.3591e-01,  2.2870e-01, -2.4384e-01,\n",
       "        -6.0966e-01, -2.6635e-01,  2.1946e-01, -1.9909e-02,  5.7904e-01,\n",
       "         7.5530e-01, -6.3776e-01, -6.0365e-01, -3.2068e-01, -4.8338e-01,\n",
       "        -8.4235e-01, -3.9114e-02,  4.8012e-01, -2.7049e-01, -6.1855e-01,\n",
       "        -7.2887e-01,  2.4225e-01,  3.3269e-01,  4.3152e-01, -2.5497e-01,\n",
       "        -4.2403e-01, -1.0147e+00, -1.5750e-02, -2.7423e-01, -1.2494e-01,\n",
       "        -2.0016e-01,  4.8426e-01,  2.1490e-01, -4.2060e-01, -4.2215e-01,\n",
       "        -3.2231e-03,  3.4388e-01,  2.6340e-01, -4.1249e-01, -3.5543e-01,\n",
       "        -2.2428e-01, -8.6987e-02, -8.7883e-01,  2.2315e-01,  2.5073e-01,\n",
       "        -3.3201e-02, -3.4819e-01,  6.6739e-03, -4.2846e-02,  2.5149e-01,\n",
       "         3.8672e-01,  8.1529e-02, -1.5161e-01,  2.1384e-01, -2.7695e-01,\n",
       "         2.2125e-01, -1.6809e-01,  7.2021e-01, -2.4760e-02, -7.4870e-01,\n",
       "         3.0091e-01, -5.5949e-01, -1.2883e-01,  2.8416e-01, -4.8912e-01,\n",
       "         8.6391e-01, -5.6682e-01, -2.3397e-01, -4.9148e-01,  5.6178e-01,\n",
       "         7.7042e-01,  3.2044e-01, -5.6792e-01, -6.1215e-03,  1.2100e+00,\n",
       "        -1.1789e-02, -2.0358e-01, -5.9396e-01, -2.0203e-01, -8.7924e-01,\n",
       "        -4.6207e-01, -2.5682e-01,  9.9208e-02,  4.5090e-01, -4.8114e-03,\n",
       "         3.3659e-01,  3.3816e-01,  5.7710e-02, -1.6724e-01, -4.1549e-01,\n",
       "        -9.8094e-01, -7.9388e-02,  1.2357e-01, -2.4852e-02,  4.5259e-01,\n",
       "        -1.4747e-01, -4.2729e-01, -1.0098e-01,  4.7728e-01,  4.5533e-01,\n",
       "        -3.6003e-01,  2.1850e-01,  2.2502e-01,  1.3961e-01, -4.2544e-01,\n",
       "        -3.8995e-02, -4.8867e-01,  4.9749e-01,  5.4677e-01,  8.1382e-01,\n",
       "        -3.0400e-01,  3.8644e-02,  3.6076e-02,  4.3679e-01,  2.6689e-01,\n",
       "         1.0291e+00,  5.6682e-01, -1.3192e-02,  2.3550e-01, -4.4970e-02,\n",
       "        -2.2165e-01,  6.5160e-02, -2.2644e-01,  3.1129e-01, -2.6938e-01,\n",
       "        -3.6079e-01, -9.6331e-02, -2.5184e-01,  5.5813e-01,  9.8418e-02,\n",
       "        -2.6760e-01, -6.1946e-01,  1.5161e-01,  1.6379e-01,  2.7450e-01,\n",
       "        -1.7087e-01, -2.6651e-01,  2.8729e-01,  5.8026e-01, -8.2545e-02,\n",
       "        -8.9690e-02,  3.3403e-02, -2.9150e-01,  6.8566e-02,  8.3394e-01,\n",
       "         5.5654e-02, -3.4182e-01, -9.0845e-01, -5.0506e-01,  7.3176e-01,\n",
       "         2.9961e-02,  4.4599e-01, -1.1027e-02,  8.1623e-01, -9.9058e-02,\n",
       "        -2.1185e-01,  5.6749e-01, -6.4657e-01, -3.4447e-01,  9.8883e-01,\n",
       "         5.1479e-01,  6.0879e-02, -3.7675e-02,  1.8368e-01, -8.8367e-01,\n",
       "         1.0163e-01, -5.4185e-03, -1.0737e-01,  2.2862e-01,  1.6417e-01,\n",
       "        -7.1829e-01, -4.5016e-01,  5.1490e-02, -3.7740e-01, -1.2133e-01,\n",
       "        -8.3608e-03,  1.1642e-01, -8.9592e-01, -7.7200e-01, -2.8535e-01,\n",
       "         2.6421e-01, -1.0876e+00, -2.9011e-01,  4.1534e-01, -1.2445e+00,\n",
       "         4.0134e-01, -7.8235e-01, -4.1335e-01,  3.3520e-01, -1.1642e+00,\n",
       "        -1.3066e-02,  3.1130e-01, -1.7375e-01, -1.4829e-01,  2.7990e-01,\n",
       "         2.9527e-02, -3.9829e-01,  4.5559e-03,  1.3331e-01, -5.5627e-01,\n",
       "         3.8095e-01, -7.2919e-01,  3.3972e-02,  2.4522e-01,  1.9602e-01,\n",
       "        -1.4570e-01, -4.0618e-01,  9.4450e-01, -5.4489e-01, -4.3444e-01,\n",
       "         5.5969e-01, -1.8327e-01,  3.3852e-01,  9.0776e-02, -9.2291e-01,\n",
       "        -2.6207e-01,  8.2758e-02, -6.5179e-02, -1.4131e-01,  2.3091e-01,\n",
       "         7.8892e-01, -3.3714e-01, -8.5526e-01, -2.5160e-01,  9.8147e-02,\n",
       "         2.6308e-01, -8.0188e-01,  9.6886e-02,  3.8630e-01, -5.6363e-01,\n",
       "        -9.9646e-01,  5.0920e-01, -2.2968e-01, -4.6172e-02,  3.5706e-01,\n",
       "        -8.7961e-02, -3.8417e-01,  6.9874e-03,  3.3860e-02, -2.7839e-01,\n",
       "         1.8435e-01, -2.9107e-01,  1.4583e-01,  5.3775e-01,  8.8839e-01,\n",
       "        -6.0998e-01,  3.3395e-01, -2.4756e-01, -4.8543e-01, -6.0474e-02,\n",
       "         9.7386e-02,  6.0502e-01,  2.3738e-01, -7.8733e-01, -2.6709e-01,\n",
       "         3.0973e-01,  2.2206e-01, -2.8343e-01, -3.9651e-01,  2.3688e-01,\n",
       "        -7.0152e-01,  4.4388e-01, -2.1333e-01,  1.4111e-02, -5.1624e-01,\n",
       "         3.0159e-01,  7.7049e-01,  1.6841e-01, -4.5963e-01,  7.3892e-01,\n",
       "         6.5939e-01,  6.1652e-01,  7.5494e-01,  5.2586e-01, -3.5319e-01,\n",
       "         6.2939e-01, -2.7841e-01,  4.6151e-01,  9.7477e-01, -9.6263e-01,\n",
       "        -6.0224e-02,  6.5167e-01,  3.7519e-01, -5.6221e-01,  2.0679e-01,\n",
       "        -1.0593e-01,  5.4411e-01, -4.5276e-02, -4.3376e-01,  5.2917e-01,\n",
       "         1.7516e-01, -3.9166e-01,  3.6231e-02,  3.2052e-02,  1.4077e-01,\n",
       "         5.9181e-01,  1.0456e+00,  1.3776e-01, -2.0848e-01,  1.5224e-01,\n",
       "         1.3958e-01,  5.3749e-01,  3.5748e-01, -3.2002e-01,  5.4689e-01,\n",
       "        -1.9662e-01,  3.3836e-01, -3.2688e-01, -1.0364e-02,  9.1065e-01,\n",
       "         6.4461e-02, -4.0760e-01,  8.2207e-01,  2.2600e-01, -4.9429e-02,\n",
       "         8.2770e-01, -1.9749e-01, -1.4983e-01,  3.8461e-01,  5.0178e-01,\n",
       "        -4.3657e-01, -2.8960e-01,  4.3559e-02,  2.3058e-01,  1.7614e-01,\n",
       "         5.4523e-01,  3.4097e-01, -1.4620e-01, -5.9213e-02,  5.6265e-01,\n",
       "         4.8125e-01, -3.2793e-01,  3.9510e-02,  2.0145e-01,  7.6171e-01,\n",
       "        -4.6387e-01, -4.5298e-01, -5.9645e-01, -2.8980e-01, -4.0440e-01,\n",
       "        -3.0702e-01, -6.5352e-03, -4.3758e-01, -2.5626e-01, -6.1143e-02,\n",
       "         1.0252e+00, -4.4234e-01, -1.1749e-01, -6.8446e-01,  9.6909e-01,\n",
       "         3.5668e-01,  5.7674e-01,  1.2227e-01, -2.2398e-01,  2.9410e-01,\n",
       "        -1.7150e-01,  3.6604e-01, -3.9944e-01,  1.7291e-01, -1.7172e-01,\n",
       "         4.1190e-01,  2.9948e-01, -6.7509e-02,  8.5313e-02,  1.4815e+00,\n",
       "        -4.0673e-01,  2.1553e-02,  3.1145e-02,  2.2321e-02, -5.2627e-01,\n",
       "        -3.4802e-02, -9.3634e-02, -4.2579e-01, -6.4130e-01,  6.4071e-02,\n",
       "         1.1533e-01,  7.6557e-01, -9.0995e-02, -2.1246e-01, -4.4053e-02,\n",
       "         4.5891e-01,  2.3333e-01, -4.0236e-01,  1.7871e-01,  4.4546e-01,\n",
       "         3.4094e-01, -4.7995e-01,  3.4939e-01,  1.0961e-01, -7.7722e-01,\n",
       "         1.1043e-01, -1.1964e+00, -2.2777e-01,  7.8304e-02,  1.0676e-01,\n",
       "        -5.8828e-01, -1.6097e-01,  9.3828e-01,  7.6024e-01, -2.3572e-01,\n",
       "        -5.4139e-01, -1.8639e-01, -3.6147e-01, -2.3667e-02, -3.7775e-01,\n",
       "        -5.8879e-02,  4.4277e-02,  1.8398e-02, -3.5151e-01,  3.2005e-01,\n",
       "        -2.5266e-01, -1.0356e-01,  5.3668e-01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warm and heat cosine similarity: 0.7890943288803101\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def extract_target_vector(template, target_word):\n",
    "    \"\"\"\n",
    "    Replace placeholder in template sentence, compute the average vector for the target word.\n",
    "    \"\"\"\n",
    "    filled_sentence = template.replace(\"[MASK]\", target_word)\n",
    "    inputs = tokenizer(filled_sentence, return_tensors=\"pt\", return_offsets_mapping=True)\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")  # Extract offset mapping\n",
    "    \n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze())\n",
    "    target_token_ids = tokenizer(target_word, add_special_tokens=False)[\"input_ids\"]\n",
    "    target_tokens = tokenizer.convert_ids_to_tokens(target_token_ids)\n",
    "    \n",
    "    # Locate the target word in the tokenized sentence\n",
    "    def find_sublist(tokens, sub_tokens):\n",
    "        n = len(sub_tokens)\n",
    "        for i in range(len(tokens) - n + 1):\n",
    "            if [t.lstrip(\"##\") for t in tokens[i:i+n]] == [st.lstrip(\"##\") for st in sub_tokens]:\n",
    "                return i, i+n\n",
    "        return None\n",
    "    \n",
    "    match = find_sublist(tokens, target_tokens)\n",
    "    if not match:\n",
    "        raise ValueError(\"Target word tokens not found in the sentence.\")\n",
    "    start_idx, end_idx = match\n",
    "\n",
    "    # Forward pass to obtain hidden states\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_hidden_state = outputs.last_hidden_state  # (1, sequence_length, hidden_size)\n",
    "\n",
    "    # Extract and average target token vectors\n",
    "    target_vectors = last_hidden_state.squeeze()[start_idx:end_idx]\n",
    "    avg_vector = target_vectors.mean(dim=0)\n",
    "    return avg_vector\n",
    "\n",
    "# Define template sentence\n",
    "template_sentence = \"I make this music sound [MASK] by manipulating its frequency content.\"\n",
    "\n",
    "word1 = \"warm\"\n",
    "word2 = \"heat\"\n",
    "vector1 = extract_target_vector(template_sentence, word1)\n",
    "vector2 = extract_target_vector(template_sentence, word2)\n",
    "\n",
    "# Compute cosine similarity\n",
    "cos_sim = F.cosine_similarity(vector1.unsqueeze(0), vector2.unsqueeze(0))\n",
    "print(word1, \"and\", word2, \"cosine similarity:\", cos_sim.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airy and heat cosine similarity: 0.6337920427322388\n"
     ]
    }
   ],
   "source": [
    "# Define multiple template sentences (more can be added if needed)\n",
    "# templates = [\n",
    "#     \"This piece of music exhibits a [MASK] timbre that shapes its overall emotional character.\",\n",
    "#     \"The sound texture of this track is distinctly [MASK], giving it a unique mood.\",\n",
    "#     \"The overall vibe of this music feels [MASK].\",\n",
    "#     \"The sound of this track is [MASK].\",\n",
    "#     \"I want to make the timbre of this audio sound [MASK].\",\n",
    "#     \"The producer has processed this audio to make it [MASK]!\"\n",
    "# ]\n",
    "templates = [\n",
    "    \"This sound feels [MASK].\",  \n",
    "    \"The overall tone of this music is [MASK].\",  \n",
    "    \"This audio conveys a [MASK] emotion, shaping the listener's perception.\",  \n",
    "    \"The resonance and texture of this recording are distinctly [MASK].\",  \n",
    "    \"The spectral balance and tonal quality of this audio feel [MASK], defining its timbre.\",  \n",
    "    \"The post-processing techniques have enhanced the sound, making it [MASK].\" \n",
    "]\n",
    "\n",
    "# Compute target word vectors across multiple templates\n",
    "def compute_avg_vector(target_word, templates):\n",
    "    vectors = [extract_target_vector(template, target_word) for template in templates]\n",
    "    return torch.stack(vectors, dim=0).mean(dim=0)  # Average across all templates\n",
    "\n",
    "target_word1 = \"airy\"\n",
    "target_word2 = \"heat\"\n",
    "vector1 = compute_avg_vector(target_word1, templates)\n",
    "vector2 = compute_avg_vector(target_word2, templates)\n",
    "\n",
    "# Compute cosine similarity\n",
    "cos_sim = F.cosine_similarity(vector1.unsqueeze(0), vector2.unsqueeze(0))\n",
    "print(target_word1, \"and\", target_word2, \"cosine similarity:\", cos_sim.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.0819e-01, -1.5756e-01,  6.3468e-01,  1.8915e-02,  1.3520e-01,\n",
       "         1.2840e-01, -5.1622e-01,  1.9215e-02,  1.7372e-01, -4.0330e-01,\n",
       "        -2.5292e-01, -8.3522e-01, -1.3366e-01,  7.3927e-01,  4.9502e-02,\n",
       "         8.6539e-01,  7.8783e-02, -2.7989e-01, -3.2030e-01, -2.2198e-01,\n",
       "         1.4575e-01, -8.1287e-02, -3.7693e-01,  5.8363e-01,  2.1823e-01,\n",
       "         1.5318e-01,  6.4739e-02,  5.1906e-01, -3.5769e-01, -4.3241e-01,\n",
       "         2.3595e-01,  9.1247e-01, -3.3900e-01, -6.1250e-01,  1.4143e-01,\n",
       "        -9.6173e-02, -3.6341e-01, -3.1309e-01, -1.2245e-01,  1.2732e-01,\n",
       "        -5.2788e-01, -5.2272e-01,  3.5619e-01, -2.8133e-01, -1.1093e-01,\n",
       "        -1.3878e-01, -1.7597e-03, -3.7658e-01, -4.2558e-01, -4.8814e-01,\n",
       "        -3.5316e-01, -1.6276e-03,  1.4911e-02, -1.2625e-01, -1.3389e-02,\n",
       "         5.6943e-01, -2.0746e-02, -7.1797e-01,  8.7373e-02, -3.8926e-01,\n",
       "        -1.9736e-01, -7.0809e-01,  1.9106e-01, -6.4776e-01, -2.2754e-01,\n",
       "         1.9925e-01, -2.1189e-01, -1.0870e+00, -4.8361e-01,  1.2518e-01,\n",
       "        -2.0024e-01,  2.3769e-01, -2.9639e-01, -3.2415e-02, -5.8281e-01,\n",
       "         3.8580e-01,  5.1414e-02,  1.0949e-01, -2.2167e-01,  5.9219e-01,\n",
       "        -1.4560e-01,  2.0098e-01, -1.2297e-01,  4.4553e-01,  2.0764e-01,\n",
       "        -2.6394e-01, -1.4587e-02,  7.0727e-01, -1.2333e-01,  1.8504e-01,\n",
       "        -1.0541e-01, -2.2567e-01,  4.0871e-02,  5.3115e-01,  1.5837e-01,\n",
       "        -8.0909e-02,  1.0603e+00, -2.0133e-01, -1.5743e-01,  5.9141e-01,\n",
       "         5.7945e-01,  4.4075e-02,  3.8215e-01, -1.6503e-01, -2.5872e-01,\n",
       "         4.4951e-01, -3.9053e-01, -5.9573e-01,  2.7499e-01,  8.0562e-01,\n",
       "         9.9950e-02, -8.1323e-02, -3.5157e-02,  6.4924e-02,  1.5865e-02,\n",
       "         2.7975e-02,  3.6217e-01, -4.6983e-01,  7.9464e-02,  1.9188e-02,\n",
       "         5.2408e-01,  1.8163e-01, -2.6343e-01,  4.6382e-01, -4.2938e-01,\n",
       "        -9.4958e-02, -3.0297e-01,  5.0160e-01, -4.1231e-01,  6.5173e-01,\n",
       "        -3.7157e-01,  3.9016e-01,  5.8443e-01, -1.6730e-01, -1.2926e-01,\n",
       "         2.1538e-01,  5.1858e-01, -9.1342e-01,  5.0804e-02, -2.9695e-01,\n",
       "        -2.5410e-02,  5.1750e-01,  4.1980e-01, -2.7654e-01, -1.1311e-01,\n",
       "         2.2546e-01,  4.0584e-01, -9.1040e-02, -3.0867e-01, -5.0229e-03,\n",
       "         7.5280e-02, -5.4071e-02, -5.9694e-01,  4.0769e-02, -4.1085e-01,\n",
       "        -2.3951e-01, -3.1298e-01,  2.7621e-01,  9.9139e-01, -3.1878e-01,\n",
       "        -1.1314e-01,  3.4572e-01, -1.3913e-01, -2.5677e-01, -1.9095e-01,\n",
       "         5.4586e-01,  2.0741e-01,  7.2689e-01, -3.7358e-01, -1.9270e-01,\n",
       "         1.3040e-01,  2.4520e-01,  3.4437e-01, -5.8649e-01, -8.1765e-02,\n",
       "         2.5628e-01,  4.7263e-02,  2.8378e-01,  7.1365e-01,  5.0302e-01,\n",
       "        -1.5601e-01,  1.2997e-01,  6.9858e-02,  4.5851e-02, -5.4392e-01,\n",
       "         1.4590e-01, -2.2676e-01, -4.6802e-01, -2.0650e-01, -4.8268e-01,\n",
       "        -2.0583e-01, -8.5564e-02, -3.9647e-01, -3.9385e-01,  5.4035e-02,\n",
       "        -3.5179e-01,  2.4387e-01,  4.0299e-01, -1.0591e-01, -2.6204e-01,\n",
       "         1.8147e-01,  3.3240e-01, -8.4573e-01, -1.1548e-01,  1.7845e-02,\n",
       "        -4.0687e-01,  2.6454e-01, -1.4574e-01, -5.7310e-01, -2.4532e-02,\n",
       "        -9.5123e-01, -3.1712e-01,  5.5085e-01,  5.7863e-01, -6.1895e-01,\n",
       "         1.6171e-01, -8.8475e-02,  2.3884e-01,  4.3278e-01, -9.7057e-01,\n",
       "         4.1169e-01,  4.0196e-01, -7.7152e-02,  7.3045e-01, -1.2913e-01,\n",
       "         7.9499e-01,  1.4147e-02, -7.1796e-01,  1.6955e-01,  5.2542e-01,\n",
       "         3.0992e-01, -4.0777e-01, -3.2692e-01, -6.0201e-01, -2.4464e-01,\n",
       "         2.4517e-01,  1.5943e-01,  3.1557e-02,  8.6546e-01, -2.9791e-01,\n",
       "        -9.3885e-02, -2.8883e-01,  5.7011e-02,  3.6928e-01,  3.7304e-01,\n",
       "        -1.0132e-01, -1.7504e-01,  1.5116e-01, -4.9829e-01,  1.3702e-01,\n",
       "        -4.3510e-01,  1.1787e-03,  1.1439e-01, -4.5417e-01, -2.6641e-01,\n",
       "        -5.2235e-01,  1.3860e-01, -3.5645e-01, -3.6563e-01,  1.5643e-01,\n",
       "         4.7150e-01,  2.4885e-01,  1.0848e+00,  1.4338e-01, -8.0012e-01,\n",
       "        -3.1026e-01,  3.0654e-01,  7.8894e-02,  3.2733e-02, -6.1181e-01,\n",
       "         8.0885e-01, -2.9189e-01,  5.7050e-01,  9.3315e-01, -2.3350e-02,\n",
       "        -8.7204e-01,  7.0483e-02, -7.1760e-02,  2.2856e-01, -5.3732e-01,\n",
       "         8.4102e-01,  1.1296e-01, -4.7672e-01, -3.6484e-01, -4.6275e-01,\n",
       "        -2.1661e-01,  1.3418e-01,  4.4686e-01,  8.8754e-02, -5.9913e-01,\n",
       "        -1.5468e-01,  2.0172e-01, -4.2678e-01,  3.4272e-01,  7.8389e-01,\n",
       "         3.8368e-01,  4.4264e-01,  8.6586e-01, -8.4018e-02, -6.0698e-01,\n",
       "        -2.5166e-01, -1.8825e-01, -4.0818e-02,  2.9978e-01, -8.1306e-01,\n",
       "         6.5965e-01, -7.8880e-03, -4.2711e-01, -4.3828e+00,  2.6687e-01,\n",
       "         4.1286e-01,  1.0826e-01, -2.8829e-01,  2.8279e-01, -1.0749e-02,\n",
       "        -3.9310e-01, -4.3558e-01, -2.8745e-03,  2.0775e-01, -5.0245e-01,\n",
       "         6.5384e-01,  2.6430e-01,  7.4800e-01, -4.0919e-01, -4.9589e-01,\n",
       "        -1.7838e-01,  9.3499e-02,  1.8415e-01, -1.5156e-01,  3.1135e-01,\n",
       "         1.2184e-01, -1.8001e-01,  8.1341e-01, -6.8879e-01,  3.7731e-03,\n",
       "         8.0926e-02, -8.6562e-01, -4.5011e-02, -2.2983e-01, -2.3186e-01,\n",
       "         4.5827e-01,  4.1096e-01,  8.0385e-01,  4.4457e-01, -2.0798e-01,\n",
       "        -2.9662e-01,  6.5907e-01, -1.2829e-02, -4.0972e-01,  6.6661e-02,\n",
       "        -2.8714e-01, -1.3616e-01,  4.6816e-01, -3.9400e-01, -1.6375e-01,\n",
       "        -5.5685e-01,  3.8714e-01,  5.2610e-01,  1.3213e-01,  6.1229e-02,\n",
       "        -3.5044e-02, -4.2175e-01,  1.5026e-01, -3.5741e-02,  8.8428e-01,\n",
       "         6.5492e-01, -3.2191e-01, -7.7675e-02, -1.6905e-01, -1.2544e-01,\n",
       "        -5.2907e-01, -2.5530e-01,  5.1234e-01,  1.2990e-01, -9.3574e-01,\n",
       "        -3.8615e-02,  5.7746e-01,  8.7342e-02,  3.3747e-01,  1.1450e-01,\n",
       "        -2.7014e-01, -9.1699e-01,  3.2998e-01, -3.3261e-02,  4.7570e-01,\n",
       "        -2.3641e-01,  6.5074e-01,  3.7469e-01, -8.7585e-02, -3.4018e-01,\n",
       "         1.5201e-01,  7.0440e-01, -4.7670e-01, -3.8492e-02, -4.0703e-04,\n",
       "         3.7633e-01, -2.0779e-01, -2.6433e-01,  5.7553e-01,  1.7319e-01,\n",
       "        -4.3053e-01,  1.0475e-01, -3.7986e-01, -3.3286e-01,  3.2930e-01,\n",
       "        -1.1247e-01,  6.9248e-01, -8.3324e-02,  4.4391e-01,  4.6034e-02,\n",
       "         3.0668e-01, -3.3317e-02,  2.8666e-01, -9.6945e-02, -6.5271e-01,\n",
       "        -4.1554e-01,  3.9918e-01,  3.3677e-01,  1.4211e-01,  9.8921e-03,\n",
       "         9.1283e-01, -3.9664e-01,  3.8254e-01, -4.9434e-01,  4.3297e-01,\n",
       "         6.5819e-01, -4.5732e-02,  2.5431e-01,  3.6906e-01,  9.3051e-01,\n",
       "        -1.2049e-01,  7.3959e-02, -4.9567e-01,  9.1726e-02, -6.1442e-01,\n",
       "         7.2341e-01, -8.5590e-01, -1.0708e+00, -5.1767e-02, -7.2070e-01,\n",
       "         6.0321e-01, -1.1830e-01,  7.3737e-02, -2.0994e-01, -1.9544e-01,\n",
       "        -1.2216e+00,  4.1623e-01, -3.2192e-01,  3.7589e-01, -1.4661e-01,\n",
       "         3.4061e-01, -2.9625e-01, -1.4431e-01,  5.4567e-02,  4.6471e-01,\n",
       "        -5.8501e-01, -5.7220e-02, -1.8261e-01,  4.7257e-01, -1.1574e-01,\n",
       "         1.6056e-01, -7.5372e-01, -3.2731e-02, -5.0617e-01,  6.4476e-01,\n",
       "        -2.0684e-01, -4.0204e-01, -3.7091e-01,  6.9179e-01, -6.5673e-02,\n",
       "         3.5718e-01,  5.8355e-01, -5.7392e-01,  1.3538e-01, -5.0674e-01,\n",
       "         4.9606e-02, -3.3775e-01, -1.9320e-01, -1.0091e-01, -4.1727e-01,\n",
       "         2.6339e-01, -6.2516e-01,  2.2216e-02,  4.1475e-01, -2.2291e-01,\n",
       "        -2.2155e-01, -7.0789e-01,  2.5077e-01,  4.4523e-01, -2.6453e-01,\n",
       "        -6.6132e-01, -3.6646e-01,  3.4210e-01,  3.0627e-01,  3.3324e-01,\n",
       "        -4.9660e-02, -1.9596e-01,  1.8298e-01, -4.7089e-01,  5.2578e-01,\n",
       "        -5.4900e-01, -6.9827e-01, -5.7165e-01,  1.8448e-01,  4.1995e-01,\n",
       "        -3.7851e-01,  2.6440e-01, -2.0015e-01,  9.9616e-01, -1.0022e+00,\n",
       "        -4.3816e-01,  6.3254e-01, -6.6012e-02, -9.9237e-02,  2.6095e-01,\n",
       "         6.0803e-02, -4.0959e-01, -9.0157e-02, -7.8897e-02, -4.8222e-01,\n",
       "        -4.9539e-01, -1.3862e-01, -2.4291e-03,  3.7445e-01, -6.8417e-01,\n",
       "        -5.6348e-01,  3.7154e-02,  1.2873e-01,  4.9442e-05,  9.0111e-02,\n",
       "         2.0714e-01,  3.4130e-01, -6.7943e-01,  1.1499e-01,  6.4319e-01,\n",
       "         4.3036e-01, -5.7018e-01, -6.9174e-01,  1.9561e-02, -6.9642e-01,\n",
       "         7.6049e-02, -3.5235e-01, -8.1050e-01,  9.1528e-02, -3.5264e-01,\n",
       "        -6.2006e-01, -7.7306e-02,  3.3016e-02, -1.9840e-01,  2.7265e-01,\n",
       "        -7.7245e-01, -3.3581e-01, -2.6002e-01,  4.1964e-01, -2.0009e-01,\n",
       "         1.1431e-01, -8.6142e-01,  1.2020e-01, -1.0501e-03, -2.1427e-01,\n",
       "        -2.0884e-01, -2.6595e-01,  7.7004e-01, -6.8149e-01,  7.1795e-02,\n",
       "         2.3012e-01, -1.6896e-01, -1.8928e-01,  2.1464e-01, -5.0246e-01,\n",
       "        -5.3524e-01,  2.5177e-01, -8.4942e-02,  3.0262e-01,  4.8882e-01,\n",
       "         5.2276e-01,  2.4675e-02, -6.7308e-01, -1.6404e-01, -2.4451e-01,\n",
       "         3.3819e-01, -1.1730e-01,  1.8699e-01,  4.9502e-01, -5.9671e-01,\n",
       "        -6.6011e-01,  9.5341e-01, -8.0519e-01,  1.2590e-02, -1.8553e-01,\n",
       "        -6.0185e-02, -2.5075e-01, -8.5054e-02, -3.1876e-01, -7.0621e-01,\n",
       "        -5.0365e-02,  1.6474e-01,  5.0614e-02,  5.9624e-01,  1.9167e-01,\n",
       "         1.0808e-01,  2.5759e-01, -1.8485e-01,  4.3976e-02,  1.4438e-02,\n",
       "         3.4314e-01,  3.8187e-01, -4.4456e-01, -3.1332e-01, -3.5554e-01,\n",
       "        -3.1764e-01,  2.3999e-01,  2.7449e-01, -2.4080e-01,  1.0180e-01,\n",
       "        -6.7314e-01,  9.0752e-02,  2.4245e-01,  3.3438e-01, -4.7246e-01,\n",
       "         3.7514e-01,  1.1119e+00, -5.5452e-01, -1.0897e-01,  4.8317e-01,\n",
       "         3.6835e-01,  3.2854e-01,  2.4648e-01,  8.9868e-02, -3.9059e-01,\n",
       "        -5.3353e-02,  2.5242e-01,  2.5276e-01,  3.9105e-01, -1.8592e-01,\n",
       "        -3.5721e-01, -2.0809e-01,  5.6667e-02, -4.9330e-02,  8.9209e-01,\n",
       "        -8.3382e-01,  1.7008e-01, -1.2479e-01,  1.3670e-01,  3.1167e-01,\n",
       "         5.5846e-01, -2.6382e-01,  3.0790e-01,  2.2017e-01, -3.3032e-01,\n",
       "        -5.6847e-02,  7.8694e-01, -1.4328e-01,  6.5713e-02,  2.1723e-01,\n",
       "         7.7295e-01,  2.4088e-01,  3.6457e-01, -4.0690e-01,  7.1629e-01,\n",
       "         5.0779e-01, -4.0252e-01, -4.5215e-02, -1.0880e-01,  5.4471e-01,\n",
       "         3.0182e-01, -4.6510e-01,  6.4991e-01, -7.6635e-02,  3.8783e-01,\n",
       "         7.8556e-01, -3.5081e-01, -1.2478e-01, -4.8746e-01, -2.5957e-01,\n",
       "        -1.6414e-01,  1.3331e-01, -2.9325e-01,  2.2082e-01,  2.5957e-01,\n",
       "        -5.9749e-01,  6.2842e-01,  6.4728e-01,  5.5230e-01,  2.8713e-01,\n",
       "         4.4974e-01,  1.2420e-01,  9.4618e-01, -1.0768e-01,  7.9714e-01,\n",
       "        -4.7911e-01, -6.0713e-01, -1.0599e-01, -2.0747e-01, -9.0088e-02,\n",
       "         1.4344e-01, -3.0517e-01, -3.9630e-01,  3.3501e-02,  2.7774e-01,\n",
       "         3.3019e-01, -7.5527e-02, -2.1161e-01, -2.1060e-01,  6.4658e-01,\n",
       "        -1.2243e-01,  5.7896e-02, -3.3645e-01, -8.8121e-03,  2.1128e-02,\n",
       "        -2.4284e-01,  1.4660e-01,  3.8853e-03,  4.0907e-01, -2.8475e-01,\n",
       "         2.5645e-01,  2.4766e-01,  2.7793e-01, -2.0342e-01,  1.6244e-01,\n",
       "        -3.9683e-01,  3.9480e-01,  2.2051e-01,  1.5180e-01, -5.2279e-01,\n",
       "         4.1628e-01, -4.0802e-01, -4.2028e-01, -2.4319e-01,  5.3922e-01,\n",
       "        -7.5314e-01,  4.6706e-01,  2.1405e-01,  5.3263e-02,  3.1554e-01,\n",
       "         2.9660e-01,  4.8625e-01,  2.2014e-01, -1.2905e-01,  4.8069e-01,\n",
       "        -5.1879e-01, -5.1879e-01,  5.0256e-01,  2.0271e-01, -2.8499e-01,\n",
       "         1.2599e-01, -4.9836e-01, -8.2477e-02,  2.5571e-01,  4.1127e-01,\n",
       "         6.5647e-01, -4.0174e-01,  1.1656e-01, -6.7288e-02, -1.9456e-01,\n",
       "        -2.7082e-01, -1.9233e-01, -4.9139e-01, -3.6109e-01, -1.7043e-01,\n",
       "         4.9008e-01,  2.3702e-01, -7.0040e-02, -2.4906e-01,  4.6995e-01,\n",
       "        -3.9159e-01, -3.2321e-01, -2.5353e-01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
